{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 11:56:23.773966: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-18 11:56:23.777318: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-18 11:56:23.786777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752850583.801558   22086 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752850583.805647   22086 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752850583.816581   22086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752850583.816596   22086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752850583.816597   22086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752850583.816598   22086 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-18 11:56:23.819866: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar e preprocessar os dados\n",
    "def load_and_preprocess_data(csv_file, time_steps, scaler):\n",
    "    # Carregar o dataset com cabeçalho\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Converter a coluna de timestamp para o formato datetime\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # A variável de entrada (X) será a coluna 'activity'\n",
    "    X = data[['activity']].values  # Usando 'activity' como feature\n",
    "    # A variável alvo (y) será a coluna 'activity'\n",
    "    y = data['activity'].values  # 'activity' como alvo\n",
    "    \n",
    "    # Normalizar as variáveis de entrada\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = scaler.transform(y.reshape(-1, 1))\n",
    "    # Criar sequências para o modelo LSTM\n",
    "    X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "    return X_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data_test(csv_file, time_steps, scaler):\n",
    "    # Carregar o dataset com cabeçalho\n",
    "    \n",
    "    data = pd.read_csv(csv_file)\n",
    "    concat_file = csv_file[:-8] + '_nov.csv'\n",
    "\n",
    "    concat_data = pd.read_csv(concat_file)\n",
    "    \n",
    "    data = pd.concat([concat_data.tail(time_steps), data])\n",
    "    # Converter a coluna de timestamp para o formato datetime\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    # A variável de entrada (X) será a coluna 'activity'\n",
    "    X = data[['activity']].values  # Usando 'activity' como feature\n",
    "    # A variável alvo (y) será a coluna 'activity'\n",
    "    y = data['activity'].values  # 'activity' como alvo\n",
    "    \n",
    "    # Normalizar as variáveis de entrada\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = scaler.transform(y.reshape(-1, 1))\n",
    "    # Criar sequências para o modelo LSTM\n",
    "    X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "    # print(data.head(31))\n",
    "    # print(scaler.inverse_transform(y_seq[0].reshape(-1, 1)))\n",
    "    return X_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar sequências temporais\n",
    "def create_sequences(X, y, time_steps):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        # print(X[i:i + time_steps], y[i + time_steps])\n",
    "        sequences.append(X[i:i + time_steps])  # Sequência de time_steps\n",
    "        targets.append(y[i + time_steps])  # Alvo correspondente ao final da sequência\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    ae = (y_pred - y_true)\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dados_para_river(X_train, y_train):\n",
    "    for i in range(len(X_train)):\n",
    "        # Convertendo a amostra para um dicionário { 'feature_0': valor, 'feature_1': valor, ... }\n",
    "        x_dict = {f'feature_{j}': X_train[i][j][0] for j in range(X_train.shape[1])}\n",
    "        \n",
    "        # Extraindo o valor escalar de y\n",
    "        y_value = y_train[i][0]\n",
    "        \n",
    "        yield x_dict, y_value  # Gerador de pares (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import evaluate\n",
    "from river import forest\n",
    "from river import metrics\n",
    "from river import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import math\n",
    "from river import forest, metrics, tree, ensemble, linear_model, preprocessing, optim\n",
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a pasta 'resultados' se não existir\n",
    "os.makedirs(\"resultados\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMFRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'    \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = forest.AMFRegressor(seed=42)\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = [] \n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/AMF_{i}.csv', index=False)\n",
    "\n",
    "    AMFRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARFRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20  # Tamanho dos lotes temporais\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = (\n",
    "                forest.ARFRegressor(seed=42)\n",
    "            )\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/ARF_{i}.csv', index=False)\n",
    "\n",
    "    ARFRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OXTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OXTRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'    \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = forest.OXTRegressor(seed=42)\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB    \n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/OTX_{i}.csv', index=False)\n",
    "\n",
    "    OXTRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaggingRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = preprocessing.StandardScaler()\n",
    "    model |= ensemble.BaggingRegressor(\n",
    "        model=linear_model.LinearRegression(intercept_lr=0.1),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "    \n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/BaR_{i}.csv', index=False)\n",
    "\n",
    "    BaggingRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWARegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "from river import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWARegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv' \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    ensemble.EWARegressor(\n",
    "        [\n",
    "            linear_model.LinearRegression(optimizer=optim.SGD(0.01), intercept_lr=.1),\n",
    "            linear_model.LinearRegression(optimizer=optim.RMSProp(), intercept_lr=.1),\n",
    "            linear_model.LinearRegression(optimizer=optim.AdaGrad(), intercept_lr=.1),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "       # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/EWA_{i}.csv', index=False)\n",
    "\n",
    "    EWARegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river.datasets import synth\n",
    "from river import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRPRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    base_model = tree.HoeffdingTreeRegressor()\n",
    "    model = ensemble.SRPRegressor(\n",
    "        model=base_model,\n",
    "        training_method=\"patches\",\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/SRP_{i}.csv', index=False)\n",
    "\n",
    "    SRPRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HardSamplingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import evaluate\n",
    "from river import imblearn\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HardSamplingRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = (\n",
    "    imblearn.HardSamplingRegressor(\n",
    "        regressor=linear_model.LinearRegression(),\n",
    "        p=.2,\n",
    "        size=30,\n",
    "        seed=42,\n",
    "    )\n",
    ")\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/HSR_{i}.csv', index=False)\n",
    "\n",
    "    HardSamplingRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HoeffdingAdaptiveTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoeffdingAdaptiveTreeregressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv' \n",
    "    chunk_size = 20 \n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = tree.HoeffdingAdaptiveTreeRegressor( seed=42 )\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/HAT_{i}.csv', index=False)\n",
    "\n",
    "    HoeffdingAdaptiveTreeregressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HoeffdingTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoeffdingTreeRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = tree.HoeffdingTreeRegressor()\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/HTR_{i}.csv', index=False)\n",
    "\n",
    "    HoeffdingTreeRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGTRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv' \n",
    "    chunk_size = 20 \n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = tree.SGTRegressor()\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/SGT_{i}.csv', index=False)\n",
    "\n",
    "    SGTRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesianLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesianLinearRegression = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = linear_model.BayesianLinearRegression()\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "        # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/BLR_{i}.csv', index=False)\n",
    "\n",
    "    BayesianLinearRegression.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20\n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/LiR_{i}.csv', index=False)\n",
    "\n",
    "    LinearRegression.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'  \n",
    "    chunk_size = 20  \n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = linear_model.PARegressor()\n",
    "\n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "\n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/PAR_{i}.csv', index=False)\n",
    "\n",
    "    PARegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv'   \n",
    "    chunk_size = 20 \n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = neighbors.KNNRegressor()\n",
    "    \n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    " \n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "    \n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/KNN_{i}.csv', index=False)\n",
    "\n",
    "    KNNRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKL2RiverRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compat\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKL2RiverRegressor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    train_csv = 'data/clstr_0_nov.csv'\n",
    "    test_csv = f'data/clstr_{i}_dec.csv' \n",
    "    chunk_size = 20   \n",
    "    scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "    X_train, y_train = load_and_preprocess_data(train_csv, chunk_size, scaler)\n",
    "    X_test, y_test = load_and_preprocess_data_test(test_csv, chunk_size, test_scaler)\n",
    "\n",
    "    model = compat.convert_sklearn_to_river(linear_model.SGDRegressor())\n",
    "    \n",
    "    mse_metric = metrics.MSE()\n",
    "    mae_metric = metrics.MAE()\n",
    "    rmse_metric = metrics.RMSE()\n",
    "\n",
    "    # Criando o gerador de dados\n",
    "    dados_river = gerar_dados_para_river(X_train, y_train)\n",
    "\n",
    "    for xi, yi in dados_river:            \n",
    "                # Treinar o modelo com o dado atual\n",
    "                model.learn_one(xi, yi)\n",
    "  \n",
    "    data = gerar_dados_para_river(X_test, y_test)\n",
    "\n",
    "    # Listas para armazenar previsões e valores reais\n",
    "    predictions = []\n",
    "    target = []\n",
    "    resultados = []\n",
    "\n",
    "    tempo_inferencias = []\n",
    "    tempo_aprendiazagem = []\n",
    "\n",
    "    for xi, yi in data:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict_one(xi)\n",
    "        t1 = time.perf_counter()\n",
    "        tempo_inferencias.append(t1 - t0)\n",
    "        predictions.append(y_pred if y_pred is not None else np.nan)\n",
    "        target.append(yi)\n",
    "                    \n",
    "        # Escrever a previsão no arquivo\n",
    "        yi_unnorm = test_scaler.inverse_transform(yi.reshape(-1, 1)).item()\n",
    "        y_pred_unnorm = test_scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).item()\n",
    "\n",
    "        # Atualizar a métrica com a predição\n",
    "        if y_pred is not None:\n",
    "            mse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            mae_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            rmse_metric.update(yi_unnorm, y_pred_unnorm)\n",
    "            \n",
    "        # Guardar os resultados na lista\n",
    "        resultados.append({\n",
    "            \"Real\": yi_unnorm,\n",
    "            \"Previsto\": y_pred_unnorm,\n",
    "            \"Erro Absoluto\": abs(y_pred_unnorm - yi_unnorm),\n",
    "            \"MAE Atual\": mae_metric.get(),\n",
    "            \"MSE Atual\": mse_metric.get(),\n",
    "            \"RMSE Atual\": rmse_metric.get()\n",
    "        })\n",
    "\n",
    "        # Treinar o modelo com o dado atual\n",
    "        ti = time.perf_counter()\n",
    "        model.learn_one(xi, yi)\n",
    "        tf = time.perf_counter()\n",
    "        tempo_aprendiazagem.append(tf - ti) \n",
    "\n",
    "    # >>> Medir o uso de memória\n",
    "    tamanho_memoria = asizeof.asizeof(model) / 1024  # em KB\n",
    "\n",
    "    # Converter para DataFrame e exibir\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    df_resultados_csv = pd.DataFrame({\n",
    "    \"Real_Requests\": df_resultados[\"Real\"].round().astype(int),\n",
    "    \"Predicted_Requests\": df_resultados[\"Previsto\"].round().astype(int)\n",
    "    })\n",
    "\n",
    "    df_resultados_csv.to_csv(f'resultados/SKL_{i}.csv', index=False)\n",
    "\n",
    "    SKL2RiverRegressor.append({\n",
    "    \"Cluster\": i,\n",
    "    \"MAE\": mae_metric.get(),\n",
    "    \"RMSE\": rmse_metric.get(),\n",
    "    \"Tempo Médio de Inferência (ms)\": round(np.mean(tempo_inferencias) * 1000, 4),  # >>> em milissegundos\n",
    "    \"Tempo Aprendizagem (ms)\": round(np.mean(tempo_aprendiazagem) * 1000, 4),\n",
    "    \"Tamanho do Modelo (KB)\": round(tamanho_memoria, 2)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista com os nomes das variáveis de resultados dos modelos\n",
    "modelos_resultados = [\n",
    "    (\"AMFRegressor\", AMFRegressor),\n",
    "    (\"ARFRegressor\", ARFRegressor),\n",
    "    (\"OXTRegressor\", OXTRegressor),\n",
    "    (\"BaggingRegressor\", BaggingRegressor),\n",
    "    (\"EWARegressor\", EWARegressor),\n",
    "    (\"SRPRegressor\", SRPRegressor),\n",
    "    (\"HardSamplingRegressor\", HardSamplingRegressor),\n",
    "    (\"HoeffdingAdaptiveTreeregressor\", HoeffdingAdaptiveTreeregressor),\n",
    "    (\"HoeffdingTreeRegressor\", HoeffdingTreeRegressor),\n",
    "    (\"SGTRegressor\", SGTRegressor),\n",
    "    (\"BayesianLinearRegression\", BayesianLinearRegression),\n",
    "    (\"LinearRegression\", LinearRegression),\n",
    "    (\"PARegressor\", PARegressor),\n",
    "    (\"KNNRegressor\", KNNRegressor),\n",
    "    (\"SKL2RiverRegressor\", SKL2RiverRegressor)\n",
    "]\n",
    "\n",
    "# Tabelas para armazenar os dados\n",
    "tabela_metricas = []\n",
    "tabela_tempos = []\n",
    "tabela_memoria = []\n",
    "\n",
    "# Iterar sobre os resultados\n",
    "for nome_modelo, resultados in modelos_resultados:\n",
    "    mae = [r.get('MAE', 0.0) for r in resultados]\n",
    "    rmse = [r.get('RMSE', 0.0) for r in resultados]\n",
    "    inf = [r.get('Tempo Médio de Inferência (ms)', 0.0) for r in resultados]\n",
    "    learn = [r.get('Tempo Aprendizagem (ms)', 0.0) for r in resultados]\n",
    "    size = [r.get('Tamanho do Modelo (KB)', 0.0) for r in resultados]\n",
    "\n",
    "    # Tabela de métricas\n",
    "    tabela_metricas.append([nome_modelo, 'MAE'] + mae)\n",
    "    tabela_metricas.append(['', 'RMSE'] + rmse)\n",
    "\n",
    "    # Tabela de tempos\n",
    "    tabela_tempos.append([nome_modelo, 'Inferência (ms)'] + inf)\n",
    "    tabela_tempos.append(['', 'Aprendizagem (ms)'] + learn)\n",
    "\n",
    "    # Tabela de memória\n",
    "    tabela_memoria.append([nome_modelo, 'Tamanho do Modelo (KB)'] + size)\n",
    "\n",
    "# Converter para DataFrames\n",
    "colunas = ['Modelo', 'Métrica', 'Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4']\n",
    "df_metricas = pd.DataFrame(tabela_metricas, columns=colunas)\n",
    "df_tempos = pd.DataFrame(tabela_tempos, columns=colunas)\n",
    "df_memoria = pd.DataFrame(tabela_memoria, columns=colunas)\n",
    "\n",
    "# Adicionar coluna de média\n",
    "for df in [df_metricas, df_tempos, df_memoria]:\n",
    "    df['Média'] = df.iloc[:, 2:7].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"resultados_completos_modelos.xlsx\") as writer:\n",
    "    df_metricas.to_excel(writer, sheet_name=\"Métricas\", index=False)\n",
    "    df_tempos.to_excel(writer, sheet_name=\"Tempos\", index=False)\n",
    "    df_memoria.to_excel(writer, sheet_name=\"Tamanho do Modelo\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online_sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
